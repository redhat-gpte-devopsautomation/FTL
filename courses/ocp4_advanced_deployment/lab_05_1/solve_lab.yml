---
- name: Solve the OCP4 on OpenStack authentication and security lab
  hosts: localhost
  gather_facts: false
  become: false
  environment:
    KUBECONFIG: "{{ lookup('env', 'HOME') }}/openstack-upi/auth/kubeconfig"
    INFRA_ID: "INFRA_ID=$(jq -r .infraID {{ lookup('env', 'HOME') }}/openstack-upi/metadata.json)"

  tasks:
  - name: Set python version
    set_fact:
      ansible_python_interpreter: /usr/bin/python3
    tags: test

  - name: Get API_HOSTNAME
    shell: "oc whoami --show-server | sed -r 's|.*//(.*):.*|\\1|'"
    register: r_api_hostname

  - name: Get INGRESS_DOMAIN
    command: "oc get ingresses.config.openshift.io cluster -o jsonpath='{.spec.domain}'"
    register: r_ingress_domain

  - name: Print variables
    debug:
      msg: "API_HOSTNAME: {{ r_api_hostname.stdout }}, INGRESS_DOMAIN: {{r_ingress_domain.stdout }}"

  - name: Set API_HOSTNAME in .bashrc
    lineinfile:
      path: $HOME/.bashrc
      regexp: "^export API_HOSTNAME"
      line: "export API_HOSTNAME={{ r_api_hostname.stdout }}"

  - name: Set INGRESS_DOMAIN in .bashrc
    lineinfile:
      path: $HOME/.bashrc
      regexp: "^export INGRESS_DOMAIN"
      line: "export INGRESS_DOMAIN={{ r_ingress_domain.stdout }}"

  # --------------------------
  # Configure TLS Certificates
  # --------------------------

  - name: Delete cluster-apiserver-tls secret
    command: oc delete secret cluster-apiserver-tls -n openshift-config
    ignore_errors: true

  - name: Create cluster-apiserver-tls secret
    command: oc create secret tls cluster-apiserver-tls --cert=$HOME/certificates/cert.pem --key=$HOME/certificates/privkey.pem -n openshift-config

  - name: Update API Servers to use new secret
    command: "oc patch apiservers.config.openshift.io cluster --type=merge -p '{\"spec\":{\"servingCerts\": {\"namedCertificates\": [{\"names\": [\"'{{ r_api_hostname.stdout }}'\"], \"servingCertificate\": {\"name\": \"cluster-apiserver-tls\"}}]}}}'"

  - name: Sleep 12 minutes for API Servers to rotate
    pause:
      minutes: 12

  - name: Find all Kube Configs
    become: yes
    find:
      file_type: file
      hidden: true
      paths:
      - /root
      - /home
      contains: "^ +certificate-authority-data:"
      patterns: "*config*"
      recurse: yes
    register: r_config_files

  - name: Fix Kube Configs
    become: yes
    replace:
      path: "{{ item.path }}"
      regexp: "^ +certificate-authority-data:.*"
    loop: "{{r_config_files.files}}"

  - name: Log back in as system:admin
    command: oc login -u system:admin

  - name: Delete Ingress tls secret if it exists
    command: oc delete secret default-ingress-tls -n openshift-ingress
    ignore_errors: true

  - name: Create Ingress tls secret
    command: oc create secret tls default-ingress-tls --cert=$HOME/certificates/fullchain.pem --key=$HOME/certificates/privkey.pem -n openshift-ingress

  - name: Update Ingress Controller configuration to use new secret
    command: "oc patch ingresscontroller.operator default --type=merge -p '{\"spec\":{\"defaultCertificate\": {\"name\": \"default-ingress-tls\"}}}' -n openshift-ingress-operator"

  - name: Sleep 1 minute for ingress controllers to rotate
    pause:
      minutes: 1

  # -------------------------------
  # Delegating Cluster Admin Rights
  # -------------------------------

  - name: Create htpasswd file
    command: touch $HOME/htpasswd

  - name: Add users to htpasswd
    command: "htpasswd -Bb $HOME/htpasswd {{ item }} openshift"
    loop:
    - "andrew"
    - "david"
    - "karla"

  - name: Delete htpasswd secret if it exists
    command: oc delete secret htpasswd -n openshift-config
    ignore_errors: true

  - name: Create htpasswd secret
    command: oc create secret generic htpasswd --from-file=$HOME/htpasswd -n openshift-config

  - name: Write htpasswd identity provider
    copy:
      content: |
        apiVersion: config.openshift.io/v1
        kind: OAuth
        metadata:
          name: cluster
        spec:
          identityProviders:
          - name: Local Password
            mappingMethod: claim
            type: HTPasswd
            htpasswd:
              fileData:
                name: htpasswd       
      dest: $HOME/oauth-htpasswd.yaml

  - name: Configure htpasswd identity provider
    command: oc apply -f $HOME/oauth-htpasswd.yaml

  - name: Delete group lab-cluster-admins if it exists
    command: oc adm groups delete lab-cluster-admins
    ignore_errors: true

  - name: Create lab-cluster-admins group
    command: oc adm groups new lab-cluster-admins david karla
  
  - name: Grant cluster-admin to lab-cluster-admins group
    command: oc adm policy add-cluster-role-to-group cluster-admin lab-cluster-admins --rolebinding-name=lab-cluster-admins
  
  - name: Disable the kubeadmin user
    command: oc delete secret kubeadmin -n kube-system
    ignore_errors: true

  # --------------------------------------
  # Configure the Container Image Registry
  # --------------------------------------

  - name: Expose the integrated container registry
    command: "oc patch configs.imageregistry.operator.openshift.io/cluster --type=merge --patch '{\"spec\":{\"defaultRoute\":true}}'"

  - name: Add simple route to acces the integrated container registry
    command: "oc patch configs.imageregistry.operator.openshift.io/cluster --type=merge --patch '{\"spec\":{\"routes\":[{\"name\":\"image-registry\", \"hostname\":\"image-registry.'{{ r_ingress_domain.stdout }}'\"}]}}'"

  - name: Delete registry-admin service account if it exists
    command: oc delete serviceaccount registry-admin -n openshift-config

  - name: Create registry-admin service account
    command: oc create serviceaccount registry-admin -n openshift-config

  - name: Grant Service Account permissions
    command: oc adm policy add-cluster-role-to-user registry-admin system:serviceaccount:openshift-config:registry-admin

  - name: Create ubi8 imagestream in openshit namespace
    command: oc create imagestream ubi8 -n openshift

  - name: Install skopeo
    become: yes
    command: yum -y install skopeo

  - name: Get Registry Admin Token
    command: oc sa get-token -n openshift-config registry-admin
    register: r_registry_admin_token
  
  - name: Copy UBI8 Image to OpenShift
    command: "skopeo copy docker://registry.access.redhat.com/ubi8:latest docker://image-registry.{{ r_ingress_domain.stdout }}/openshift/ubi8:latest --dest-creds -:{{ r_registry_admin_token.stdout }}"

  - name: Pull image to bastion
    command: "podman pull image-registry.{{ r_ingress_domain.stdout }}/openshift/ubi8:latest --creds -:{{ r_registry_admin_token.stdout }}"

  # -----------------------------
  # Configure SSH access to nodes
  # -----------------------------

  - name: Create project node-ssh
    command: oc new-project node-ssh

  - name: Create new build
    shell: |
      oc new-build openshift/ubi8:latest --name=node-ssh --dockerfile - <<EOF
      FROM unused
      RUN dnf install -y openssh-clients
      CMD ["sleep", "infinity"]
      EOF

  - name: Wait for Build to finish
    shell: oc get pod node-ssh-1-build -n node-ssh | grep -v STATUS | awk -c '{print $3}'
    register: r_build_pod
    retries: 20
    delay: 5
    until: r_build_pod.stdout is match( 'Completed' )

  - name: Get GUID
    command: echo $GUID
    register: r_guid
  
  - name: Create node-ssh secret
    command: "oc create secret generic node-ssh --from-file=id_rsa=$HOME/.ssh/{{ r_guid.stdout }}key.pem -n node-ssh"
  
  - name: Create Deployment File
    copy:
      content: |
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          creationTimestamp: null
          labels:
            app: node-ssh
          name: node-ssh
        spec:
          replicas: 1
          selector:
            matchLabels:
              app: node-ssh
          strategy: {}
          template:
            metadata:
              creationTimestamp: null
              labels:
                app: node-ssh
            spec:
              containers:
              - image: image-registry.openshift-image-registry.svc:5000/node-ssh/node-ssh:latest
                name: node-ssh
                resources: {}
                volumeMounts:
                - name: node-ssh
                  mountPath: /.ssh
              volumes:
              - name: node-ssh
                secret:
                  secretName: node-ssh
                  defaultMode: 0600
      dest: "$HOME/node-ssh.deployment.yaml"
  
  - name: Create Deployment
    command: oc create -f $HOME/node-ssh.deployment.yaml
  
  - name: Create new SSH Key
    command: ssh-keygen -t rsa -f $HOME/.ssh/node.id_rsa -N ''
  
  - name: Read SSH Key
    slurp:
      src: $HOME/.ssh/node.id_rsa.pub
    register: r_id_rsa_pub

  - name: Update machineconfig 99-worker-ssh
    shell: "oc patch machineconfig 99-worker-ssh --type=json --patch='[{\"op\":\"add\", \"path\":\"/spec/config/passwd/users/0/sshAuthorizedKeys/-\", \"value\":\"{{ r_id_rsa_pub['content'] | b64decode }}\"}]'"

  - name: Update machineconfig master-99-ssh
    shell: "oc patch machineconfig 99-master-ssh --type=json --patch='[{\"op\":\"add\", \"path\":\"/spec/config/passwd/users/0/sshAuthorizedKeys/-\", \"value\":\"{{ r_id_rsa_pub['content'] | b64decode }}\"}]'"

  - name: Delete SSH Secret in node-ssh
    command: oc delete secret node-ssh -n node-ssh

  - name: Create new SSH Secret in node-ssh
    command: oc create secret generic node-ssh --from-file=id_rsa=$HOME/.ssh/node.id_rsa -n node-ssh

  - name: Kill node-ssh pod to force reload of secret
    command: oc delete pod -l app=node-ssh -n node-ssh

  - name: Print finish statement
    debug:
      msg: "Wait until all nodes have finished redeploying. This takes 10-15 minutes. Then you can try connecting to your nodes."
